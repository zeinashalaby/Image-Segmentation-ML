{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9355218,"sourceType":"datasetVersion","datasetId":5671336},{"sourceId":9437786,"sourceType":"datasetVersion","datasetId":5734792}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div align='center'><font size=\"5\" color='#353B47'>Image Segmentation</font></div>\n<div align='center'><font size=\"4\" color=\"#353B47\">Using U-Net with Keras</font></div>\n<br>\n<hr>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"chap2\"><h1 style=\"color:white;background:#5963ab;border-radius:5px;padding:30px;font-family:'Arial', cursive;font-size:50px;text-align:center\">Setup</h1></div>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport zipfile\nimport numpy as np\nimport random\nimport os\nfrom tqdm import tqdm\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom tqdm import tqdm\n\n# Set the random seed correctly\nSEED = 42\nnp.random.seed(SEED)\n\n# Paths for the dataset (no need to unzip)\nTRAIN_PATH = '/kaggle/input/dataset3/data/images'  # Adjust this path if needed\nTEST_PATH = '/kaggle/input/dataset3/data/labels'   # Adjust this path if needed\n\n# Image specifications\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3\n\n# Get list of all subfolders for train and test\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]\n\n# Define placeholders for training data\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)  # Changed to np.bool_\n\n# Loop through all training IDs to read images and masks\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):  \n    # Get the path to the image and mask directories\n    path = os.path.join(TRAIN_PATH, id_)  # Adjust path correctly\n    \n    # Read and resize the image\n    img = imread(path + '/images/' + id_ + '.tif')[:, :, :IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    \n    # Store the processed image in the X_train array\n    X_train[n] = img\n    \n    # Initialize an empty mask\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)  # Changed to np.bool_\n    \n    # Loop through each file in the masks directory\n    for mask_file in next(os.walk(path + '/masks/'))[2]:  \n        # Read and resize the mask, adding an extra dimension\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n        \n        # Merge the masks\n        mask = np.maximum(mask, mask_)\n    \n    # Store the processed mask in the Y_train array\n    Y_train[n] = mask\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an empty array for test images with dimensions as (number of test images, height, width, channels)\n# The datatype for the array is uint8 which can hold values from 0 to 255\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n\n# Initialize an empty list to store the original sizes of the test images\nsizes_test = []\n\n# Loop through all the test_ids\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    \n    # Get the path to the test image\n    path = TEST_PATH + id_\n    \n    # Read the image and keep the first IMG_CHANNELS channels\n    img = imread(path + '/images/' + id_ + '.tif')[:, :, :IMG_CHANNELS]\n    \n    # Append the original size of the image to sizes_test list\n    sizes_test.append([img.shape[0], img.shape[1]])\n    \n    # Resize the image to IMG_HEIGHT x IMG_WIDTH while keeping the pixel values\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    \n    # Store the processed image into the X_test array at index n\n    X_test[n] = img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div id=\"chap4\"><h1 style=\"color:white;background:#5963ab;border-radius:5px;padding:30px;font-family:'Arial', cursive;font-size:50px;text-align:center\">Training Unet</h1></div>","metadata":{}},{"cell_type":"code","source":"# Create a function for a convolution block\ndef conv_block(inputs, num_filters):\n    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation=\"relu\", \n                               kernel_initializer=\"he_normal\", padding=\"same\")(inputs)\n    x = tf.keras.layers.Dropout(0.1)(x)\n    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation=\"relu\", \n                               kernel_initializer=\"he_normal\", padding=\"same\")(x)\n    return x\n\n# Create a function for the expanding path\ndef upsample_block(inputs, conv_prev, num_filters):\n    up = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding=\"same\")(inputs)\n    concat = tf.keras.layers.concatenate([up, conv_prev])\n    conv = conv_block(concat, num_filters)\n    return conv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inputs\ninputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n\n# Normalization\ns = tf.keras.layers.Lambda(lambda x: x/255.0)(inputs) \n\n# Contraction path\nc1 = conv_block(s, 16)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\nc2 = conv_block(p1, 32)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\nc3 = conv_block(p2, 64)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\nc4 = conv_block(p3, 128)\np4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n\nc5 = conv_block(p4, 256)\n\n# Expansive path\nc6 = upsample_block(c5, c4, 128)\nc7 = upsample_block(c6, c3, 64)\nc8 = upsample_block(c7, c2, 32)\nc9 = upsample_block(c8, c1, 16)\n\n# Output layer\noutputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n\n# Compilation\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callbacks\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model.keras', verbose=1, save_best_only=True)  # Changed to .keras\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n    tf.keras.callbacks.TensorBoard(log_dir='logs')\n]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.fit(\n    X_train, \n    Y_train, \n    validation_split = 0.1, \n    batch_size = 16, \n    epochs = 25, \n    callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div id=\"chap5\"><h1 style=\"color:white;background:#5963ab;border-radius:5px;padding:30px;font-family:'Arial', cursive;font-size:50px;text-align:center\">Inference</h1></div>","metadata":{}},{"cell_type":"code","source":"# Predictions\nidx = random.randint(0, len(X_train))\n\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose = 1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose = 1)\npreds_test = model.predict(X_test, verbose = 1)\n\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to display images\ndef display_images(image):\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select a random index from training set\nix = random.randint(0, len(preds_train_t))\n\n# Display the input image\nprint(\"Input Image:\")\ndisplay_images(X_train[ix])\n\n# Display the ground truth mask\nprint(\"Ground Truth Mask:\")\ndisplay_images(np.squeeze(Y_train[ix]))\n\n# Display the predicted mask\nprint(\"Predicted Mask:\")\ndisplay_images(np.squeeze(preds_train_t[ix]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select a random index from validation set\nix = random.randint(0, len(preds_val_t))\n\n# Calculate the index from where validation data starts\nval_data_start = int(X_train.shape[0] * 0.9)\n\n# Display the validation input image\nprint(\"Validation Input Image:\")\ndisplay_images(X_train[val_data_start:][ix])\n\n# Display the validation ground truth mask\nprint(\"Validation Ground Truth Mask:\")\ndisplay_images(np.squeeze(Y_train[val_data_start:][ix]))\n\n# Display the validation predicted mask\nprint(\"Validation Predicted Mask:\")\ndisplay_images(np.squeeze(preds_val_t[ix]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from flask import Flask, render_template, request\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np\n\napp = Flask(__name__)\n\n\nmodel=load_model('model.keras')\n\n\nmodel.make_predict_function()\n\ndef predict_label(img_path):\n        i = image.load_img(img_path, target_size=(28,28), grayscale=True)\n        i = image.img_to_array(i)\n        resize_image= np.array([i], order='C')\n        img_out = image.array_to_img(resize_image.reshape(28,28,1))\n        img_out.save(img_path)\n        p = model.predict(resize_image)\n        return p.argmax()\n\n# routes\n@app.route(\"/\", methods=['GET', 'POST'])\ndef main():\n    return render_template(\"index.html\")\n\n@app.route(\"/about\")\ndef about_page():\n    return \"My project \"\n\n@app.route(\"/submit\", methods = ['GET', 'POST'])\ndef get_output():\n        if request.method == 'POST':\n                img = request.files['my_image']\n\n                img_path = \"data/\" + img.filename\t\n                img.save(img_path)\n\n                p = predict_label(img_path)\n\n        return render_template(\"index.html\", prediction = p, img_path = img_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}